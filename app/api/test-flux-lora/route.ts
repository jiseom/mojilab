import { NextRequest, NextResponse } from 'next/server';
import Replicate from 'replicate';
import sharp from 'sharp';
import { GoogleGenerativeAI } from '@google/generative-ai';
import { createClient } from '@supabase/supabase-js';
import { supabase } from '@/lib/supabase';

const replicate = new Replicate({
  auth: process.env.REPLICATE_API_TOKEN || '',
});

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY || '');

// Supabase client for direct DB save
function getSupabaseClient() {
  const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL;
  const supabaseServiceKey = process.env.SUPABASE_SERVICE_ROLE_KEY;

  if (!supabaseUrl || !supabaseServiceKey) {
    throw new Error('Missing Supabase environment variables');
  }

  return createClient(supabaseUrl, supabaseServiceKey);
}

async function resolveReplicateModelById(id: string): Promise<string> {
  const supabase = getSupabaseClient();

  const { data, error } = await supabase
    .from('lora_models')
    .select('replicate_model_name')
    .eq('id', id)
    .single();

  if (error || !data?.replicate_model_name) {
    throw new Error(`Invalid model id: ${id}`);
  }
  return data.replicate_model_name as string;
}



interface ConvertRequest {
  id?: string;
  images?: string[]; // base64 data URLs (optional - img2img mode)
  prompts?: string[]; // text prompts (optional - text2img mode)
  mode?: 'text2img' | 'img2img' | 'preview' | 'batch'; // generation mode
  style?: 'pencil' | 'pen'; // style variant (for sketch page)
  theme?: string; // theme for emotion generation (for sketch page)
  referenceImage?: string; // reference image for batch mode (for character consistency)
  monochromeOnly?: boolean; // í‘ë°± ì „ìš© ì˜µì…˜ (ê¸°ë³¸ê°’: true)
  // ìë™ ì €ì¥ ì˜µì…˜
  saveToDb?: boolean; // trueë©´ ìƒì„± ì™„ë£Œ í›„ ìë™ìœ¼ë¡œ DBì— ì €ì¥
  userId?: string; // ì €ì¥ì‹œ í•„ìš”í•œ ì‚¬ìš©ì ID
  character?: string; // ì €ì¥ì‹œ í•„ìš”í•œ ìºë¦­í„° ì„¤ëª…
  emotionNames?: string[]; // ê° ì´ë¯¸ì§€ì˜ ê°ì • ì´ë¦„ (promptsì™€ 1:1 ë§¤ì¹­)
}

// ìŠ¤íƒ€ì¼ë³„ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
const STYLE_PROMPTS = {
  pencil: `soft pencil sketch, light graphite strokes, gentle pencil shading, delicate line art, thin sketchy lines, subtle pencil texture, hand-drawn with soft strokes, loose pencil drawing, light sketchy style, faint outlines`,
  pen: `VERY BOLD thick black marker pen, EXTREMELY STRONG ink outlines, HEAVY black borders, THICK chunky pen strokes, bold cartoon style, SOLID black lines, confident bold ink drawing, thick marker technique, HEAVY pen pressure, STRONG contrast, clean bold style`
};

// ì¹´í…Œê³ ë¦¬ ëª©ë¡
const VALID_CATEGORIES = ['cute', 'daily', 'work', 'love', 'funny', 'animal', 'food', 'seasonal'] as const;

// í…Œë§ˆ/ìºë¦­í„°ì—ì„œ ì¹´í…Œê³ ë¦¬ ìë™ ë¶„ë¥˜ (Gemini ì‚¬ìš©)
async function classifyCategories(theme: string, character: string): Promise<string[]> {
  try {
    const model = genAI.getGenerativeModel({ model: 'gemini-2.0-flash-exp' });

    const prompt = `Classify this emoticon theme and character into categories.

Theme: ${theme}
Character: ${character}

Available categories:
- cute: ê·€ì—¬ìš´, ì‚¬ë‘ìŠ¤ëŸ¬ìš´ ìºë¦­í„°
- daily: ì¼ìƒ, ìƒí™œ, ë°±ìˆ˜, ì§‘ìˆœì´, ì§‘ëŒì´, íœ´ì‹
- work: ì§ì¥, íšŒì‚¬, ì—…ë¬´, ì¶œê·¼, í‡´ê·¼
- love: ì—°ì• , ì‚¬ë‘, ì»¤í”Œ, ì¸
- funny: ì›ƒê¸´, ìœ ë¨¸, ê°œê·¸
- animal: ë™ë¬¼ ìºë¦­í„° (ê³ ì–‘ì´, ê°•ì•„ì§€, í† ë¼ ë“±)
- food: ìŒì‹, ë¨¹ë°©, ìš”ë¦¬
- seasonal: ê³„ì ˆ, ëª…ì ˆ, í¬ë¦¬ìŠ¤ë§ˆìŠ¤, ì„¤ë‚ , ì¶”ì„, ì—¬ë¦„, ê²¨ìš¸

Return ONLY a JSON array of matching category slugs (1-3 categories).
Example: ["cute", "animal"]

Categories:`;

    const result = await model.generateContent(prompt);
    const text = result.response.text().trim();

    // JSON íŒŒì‹±
    const match = text.match(/\[.*\]/);
    if (match) {
      const categories = JSON.parse(match[0]) as string[];
      // ìœ íš¨í•œ ì¹´í…Œê³ ë¦¬ë§Œ í•„í„°ë§
      return categories.filter(c => VALID_CATEGORIES.includes(c as any));
    }

    return ['daily']; // ê¸°ë³¸ê°’
  } catch (error) {
    console.error('Category classification failed:', error);
    return ['daily']; // ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’
  }
}

// ìºë¦­í„° ì„¤ëª…ì„ ì˜ì–´ë¡œ ë²ˆì—­ (ìºì‹œ ì‚¬ìš©)
const translationCache = new Map<string, string>();

async function translateToEnglish(text: string): Promise<string> {
  // ìºì‹œ í™•ì¸
  if (translationCache.has(text)) {
    console.log(`Using cached translation for: "${text}"`);
    return translationCache.get(text)!;
  }

  try {
    const model = genAI.getGenerativeModel({ model: 'gemini-2.0-flash-exp' });

    const prompt = `Translate this character description to English for AI image generation.
Keep it concise and clear. Only output the English translation, nothing else.

Korean: ${text}
English:`;

    const result = await model.generateContent(prompt);
    const translation = result.response.text().trim();

    console.log(`Translation: "${text}" â†’ "${translation}"`);

    // ìºì‹œ ì €ì¥
    translationCache.set(text, translation);

    return translation;
  } catch (error) {
    console.error('Translation failed:', error);
    // ë²ˆì—­ ì‹¤íŒ¨ì‹œ ì›ë³¸ ë°˜í™˜
    return text;
  }
}

// íˆ¬ëª… ë°°ê²½ì„ í°ìƒ‰ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
async function convertTransparentToWhite(dataUrl: string): Promise<string> {
  try {
    // data URLì—ì„œ base64 ë°ì´í„° ì¶”ì¶œ
    const base64Data = dataUrl.replace(/^data:image\/\w+;base64,/, '');
    const imageBuffer = Buffer.from(base64Data, 'base64');

    // í°ìƒ‰ ë°°ê²½ìœ¼ë¡œ í•©ì„±
    const processedBuffer = await sharp(imageBuffer)
      .flatten({ background: { r: 255, g: 255, b: 255 } }) // íˆ¬ëª… â†’ í°ìƒ‰
      .png()
      .toBuffer();

    // base64ë¡œ ë‹¤ì‹œ ë³€í™˜
    const processedBase64 = processedBuffer.toString('base64');
    return `data:image/png;base64,${processedBase64}`;
  } catch (error) {
    console.error('Error converting transparent background:', error);
    // ë³€í™˜ ì‹¤íŒ¨ì‹œ ì›ë³¸ ë°˜í™˜
    return dataUrl;
  }
}

export async function POST(request: NextRequest) {
  try {
    const body: ConvertRequest = await request.json();
    const {
      id,
      images, prompts, mode = 'text2img', style, theme, referenceImage, monochromeOnly = true,
      saveToDb = false, userId, character, emotionNames
    } = body;

    // mode ì •ê·œí™”: preview/batch â†’ text2img
    const actualMode = mode === 'preview' || mode === 'batch' ? 'text2img' : mode;
    const isPreviewMode = mode === 'preview';
    const isBatchMode = mode === 'batch';

    // ëª¨ë“œì— ë”°ë¼ ìœ íš¨ì„± ê²€ì‚¬
    if (mode === 'img2img' && (!images || !Array.isArray(images) || images.length === 0)) {
      return NextResponse.json(
        { error: 'Missing required field for img2img mode: images (array of base64 data URLs)' },
        { status: 400 }
      );
    }

    if ((actualMode === 'text2img' || isPreviewMode || isBatchMode) && (!prompts || !Array.isArray(prompts) || prompts.length === 0)) {
      return NextResponse.json(
        { error: 'Missing required field for text2img/preview/batch mode: prompts (array of text prompts)' },
        { status: 400 }
      );
    }

    if (!process.env.REPLICATE_API_TOKEN) {
      return NextResponse.json(
        { error: 'REPLICATE_API_TOKEN not configured' },
        { status: 500 }
      );
    }

    const isText2Img = actualMode === 'text2img';
    const itemCount = isText2Img ? prompts!.length : images!.length;

    console.log(`Generating ${itemCount} images with FLUX LoRA (${mode} mode${style ? `, style: ${style}` : ''}${theme ? `, theme: ${theme}` : ''})...`);

    let modelName: string | null = null;

    if (!id) {
      return NextResponse.json(
      { error: 'model id is required' },
      { status: 400 }
     );
    }

    // idê°€ ìˆìœ¼ë©´ ë°˜ë“œì‹œ resolve
    const model = await resolveReplicateModelById(id);
    	
    const results = [];

    // ì´ë¯¸ì§€/í”„ë¡¬í”„íŠ¸ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ìƒì„± (rate limit íšŒí”¼)
    for (let i = 0; i < itemCount; i++) {
      const startTime = Date.now();

      console.log(`Generating ${i + 1}/${itemCount} (${mode})...`);

      try {
        let inputParams: any = {
          model: 'dev',
          go_fast: false,
          lora_scale: 1,
          megapixels: '1',
          num_outputs: 1,
          aspect_ratio: '1:1',
          output_format: 'webp',
          guidance_scale: 3,
          output_quality: 80,
          extra_lora_scale: 1,
          num_inference_steps: 28,
        };

        if (isText2Img) {
          // text2img ëª¨ë“œ: 2ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤ (ìƒì„± â†’ ì •ì œ)
          let userPrompt = prompts![i];

          // ì˜ì–´ë¡œ ë²ˆì—­
          const translatedPrompt = await translateToEnglish(userPrompt);

          // í…Œë§ˆê°€ ìˆìœ¼ë©´ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
          let finalPrompt = translatedPrompt;
          if (theme && isBatchMode) {
            const translatedTheme = await translateToEnglish(theme);
            finalPrompt = `${translatedPrompt}, in context of ${translatedTheme}`;
          }

          // ìŠ¤íƒ€ì¼ë³„ í”„ë¡¬í”„íŠ¸ ì ìš©
          const stylePrefix = style ? STYLE_PROMPTS[style] + ', ' : 'hand-drawn sketch with marker pen strokes, pencil texture, rough line art style, thick uneven marker lines, casual pencil shading, sketchy stroke-based drawing, ';

          // í‘ë°± vs ì»¬ëŸ¬ í”„ë¡¬í”„íŠ¸
          const colorPrompt = monochromeOnly
            ? 'black and white only, grayscale shading, NO colors, monochrome line art, pencil hatching for shadows, simple gray tones, NO blush, NO blushing'
            : 'colorful, vibrant colors, soft pastel tones';

          const fullPrompt = `${finalPrompt}, ${stylePrefix}strong black outlines, bold black borders, thick black contour lines, clear black edges, ${colorPrompt}, chibi proportions with slightly bigger head, compact body, very short stubby limbs, small arms and legs, NO tall body, NO long limbs, asymmetric wonky proportions, crooked uneven features, lopsided asymmetric face, simple flat dash eyes (- -) or simple dot eyes (â€¢ â€¢), NO round eyes, NO circular pupils, NO eyeballs, NO shiny eyes, absolutely NO long tail, short stubby tail only or no tail, imperfect hand-drawn shapes, loose strokes, white background`;

          // Step 1: text2img ìƒì„±
          inputParams.prompt = fullPrompt;

          console.log(`  â†’ Step 1/2: text2img generation with prompt: "${userPrompt}" â†’ "${translatedPrompt}"${style ? ` (${style} style)` : ''}${theme && isBatchMode ? ` [theme: ${theme}]` : ''}`);
          console.log(`  â†’ Starting Step 1...`);
        } else {
          // img2img ëª¨ë“œ: ì´ë¯¸ì§€ + í”„ë¡¬í”„íŠ¸
          const imageDataUrl = images![i];
          const whiteBackgroundImage = await convertTransparentToWhite(imageDataUrl);

          // í”„ë¡¬í”„íŠ¸ê°€ ìˆìœ¼ë©´ ì‚¬ìš© (img2img ëª¨ë“œì—ì„œ ê° ê°ì •ë³„ í”„ë¡¬í”„íŠ¸)
          let finalPrompt = '';
          if (prompts && prompts[i]) {
            const userPrompt = prompts[i];

            // ì˜ì–´ë¡œ ë²ˆì—­
            const translatedPrompt = await translateToEnglish(userPrompt);

            // í…Œë§ˆê°€ ìˆìœ¼ë©´ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
            if (theme) {
              const translatedTheme = await translateToEnglish(theme);
              finalPrompt = `${translatedPrompt}, in context of ${translatedTheme}`;
            } else {
              finalPrompt = translatedPrompt;
            }

            console.log(`  â†’ Translated prompt: "${userPrompt}" â†’ "${translatedPrompt}"`);
          }

          // ìŠ¤íƒ€ì¼ë³„ í”„ë¡¬í”„íŠ¸ ì ìš©
          const stylePrefix = style ? STYLE_PROMPTS[style] + ', ' : 'rough doodle sketch, messy hand-drawn lines, sketchy unpolished style, ';

          // í‘ë°± vs ì»¬ëŸ¬ í”„ë¡¬í”„íŠ¸ (img2img)
          const colorPromptImg = monochromeOnly
            ? 'black and white only, grayscale shading, NO colors, monochrome line art, pencil hatching for shadows, simple gray tones, NO blush, NO blushing'
            : 'colorful, vibrant colors, soft pastel tones';

          const stylePrompt = finalPrompt
            ? `${finalPrompt}, ${stylePrefix}strong black outlines, bold black borders, thick black contour lines, clear black edges, ${colorPromptImg}, chibi proportions with slightly bigger head, compact body, very short stubby limbs, small arms and legs, NO tall body, NO long limbs, with small simple flat eyes (NO sparkling or shining eyes, NO round pupils), asymmetric crooked face shape, wonky irregular proportions, imperfect shapes, casual drawing, loose strokes, absolutely NO long tail, short stubby tail only or no tail, white background`
            : `${stylePrefix}strong black outlines, bold black borders, thick black contour lines, clear black edges, ${colorPromptImg}, chibi proportions with slightly bigger head, compact body, very short stubby limbs, small arms and legs, NO tall body, NO long limbs, with small simple flat eyes (NO sparkling or shining eyes, NO round pupils), asymmetric crooked face shape, wonky irregular proportions, imperfect shapes, casual drawing, loose strokes, white background`;

          inputParams.image = whiteBackgroundImage;
          inputParams.prompt = stylePrompt;
          inputParams.prompt_strength = 0.25; // ë§¤ìš° ë‚®ì€ ê°•ë„ë¡œ í¬ì¦ˆ ì™„ì „ ì¬ì‘ì„±
          console.log(`  â†’ Converting image with img2img (strength: 0.25)${finalPrompt ? ` (prompt: "${finalPrompt}")` : ''}${style ? ` (${style} style)` : ''}`);
        }

        const output = await replicate.run(model as any, { input: inputParams });
        console.log(`  âœ… Step 1 complete`);

        let imageUrl: string;

        if (Array.isArray(output)) {
          imageUrl = String(output[0]);
        } else if (typeof output === 'string') {
          imageUrl = output;
        } else if (output && typeof output === 'object') {
          const urlField = (output as any).url || (output as any).output || (output as any)[0];
          if (urlField) {
            imageUrl = String(urlField);
          } else {
            throw new Error('Cannot find URL in output object');
          }
        } else {
          throw new Error('Invalid output format: ' + typeof output);
        }

        if (typeof imageUrl !== 'string' || !imageUrl.startsWith('http')) {
          throw new Error('Invalid URL returned from Replicate');
        }

        let finalUrl = imageUrl;

        // text2img ëª¨ë“œì¸ ê²½ìš°: Step 2ë¡œ img2img ì •ì œ ì‹¤í–‰ (ìºë¦­í„° ì¼ê´€ì„±)
        // - preview ëª¨ë“œ: ìŠ¤í‚µ (1-passë§Œ)
        // - batch ëª¨ë“œ: Step 1 ê²°ê³¼ë¥¼ ì •ì œí•˜ì—¬ LoRA ìŠ¤íƒ€ì¼ ì¼ê´€ì„± ì¶”ê°€
        // - ì¼ë°˜ text2img: ê°™ì€ ì´ë¯¸ì§€ë¡œ self-refinement
        if (isText2Img && !isPreviewMode) {
          // Step 1ê³¼ Step 2 ì‚¬ì´ì— ëŒ€ê¸° (rate limit)
          console.log(`  â†’ Waiting 15s before Step 2 (rate limit: 6/min)...`);
          await new Promise(resolve => setTimeout(resolve, 15000));

          console.log(`  â†’ Step 2/2: img2img refinement (keeping pose from Step 1)`);

          // Step 2ëŠ” í•­ìƒ Step 1 ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •ì œ
          const step2Output = await replicate.run(model as any, {
            input: {
              image: imageUrl, // Step 1 ê²°ê³¼ ì‚¬ìš© (í¬ì¦ˆ ìœ ì§€)
              prompt: inputParams.prompt, // ê°™ì€ í”„ë¡¬í”„íŠ¸
              model: 'dev',
              go_fast: false,
              lora_scale: 1,
              megapixels: '1',
              num_outputs: 1,
              aspect_ratio: '1:1',
              output_format: 'webp',
              guidance_scale: 3,
              output_quality: 80,
              prompt_strength: 0.3, // ë‚®ì€ ê°•ë„ë¡œ í¬ì¦ˆëŠ” ê·¸ëŒ€ë¡œ, LoRA ìŠ¤íƒ€ì¼ë§Œ ì •ì œ
              extra_lora_scale: 1,
              num_inference_steps: 28,
            },
          });

          // Step 2 ê²°ê³¼ ì¶”ì¶œ
          if (Array.isArray(step2Output)) {
            finalUrl = String(step2Output[0]);
          } else if (typeof step2Output === 'string') {
            finalUrl = step2Output;
          } else if (step2Output && typeof step2Output === 'object') {
            const urlField = (step2Output as any).url || (step2Output as any).output || (step2Output as any)[0];
            if (urlField) {
              finalUrl = String(urlField);
            }
          }

          console.log(`  âœ… Step 2 complete: ${finalUrl}`);
        }

        const convertedUrl = finalUrl;

        // ë°°ê²½ ì œê±°ëŠ” ì¼ë‹¨ ìŠ¤í‚µ (í° ë°°ê²½ ê·¸ëŒ€ë¡œ ë‹¤ìš´ë¡œë“œ)
        console.log(`  â†’ Skipping background removal (returning original)...`);
        let transparentDataUrl: string | null = null;

        try {
          // ì›ë³¸ ì´ë¯¸ì§€ë¥¼ PNGë¡œ ë³€í™˜ë§Œ
          const imageResponse = await fetch(convertedUrl);
          const imageBuffer = Buffer.from(await imageResponse.arrayBuffer());

          // 360x360 ë¦¬ì‚¬ì´ì¦ˆ
          const resizedBuffer = await sharp(imageBuffer)
            .resize(360, 360, {
              fit: 'contain',
              background: { r: 255, g: 255, b: 255 } // í°ìƒ‰ ë°°ê²½
            })
            .png()
            .toBuffer();

          transparentDataUrl = `data:image/png;base64,${resizedBuffer.toString('base64')}`;
          console.log(`  âœ… PNG conversion complete (white background)`);
        } catch (error: any) {
          console.error(`  âš ï¸ PNG conversion failed:`, error.message);
        }

        const elapsedTime = Date.now() - startTime;
        console.log(`âœ… ${mode} ${i + 1}/${itemCount} complete (took ${(elapsedTime / 1000).toFixed(1)}s):`, convertedUrl);

        results.push({
          index: i,
          ...(isText2Img ? { prompt: prompts![i] } : { originalDataUrl: images![i] }),
          generatedUrl: convertedUrl,
          transparentDataUrl, // íˆ¬ëª… ë°°ê²½ ë²„ì „
          success: true,
        });

      } catch (error: any) {
        console.error(`âŒ Failed to generate ${i + 1}:`, error.message);

        results.push({
          index: i,
          ...(isText2Img ? { prompt: prompts![i] } : { originalDataUrl: images![i] }),
          generatedUrl: null,
          success: false,
          error: error.message,
        });
      }

      // rate limit: 6/min = ë‹¤ìŒ í”„ë¡¬í”„íŠ¸ ì „ ë¬´ì¡°ê±´ ëŒ€ê¸°
      if (i < itemCount - 1) {
        // preview ëª¨ë“œëŠ” ë” ì§§ì€ ëŒ€ê¸° (1-passë§Œ í•˜ë¯€ë¡œ)
        const waitTime = isPreviewMode ? 2000 : 15000;
        console.log(`â³ Waiting ${waitTime / 1000}s before next prompt (rate limit: 6/min)...`);
        await new Promise(resolve => setTimeout(resolve, waitTime));
      }
    }

    const successCount = results.filter(r => r.success).length;
    console.log(`âœ… Generation complete: ${successCount}/${itemCount} successful`);

    // ìë™ ì €ì¥ ì˜µì…˜ì´ í™œì„±í™”ë˜ë©´ DBì— ë°”ë¡œ ì €ì¥
    let savedSeriesId: string | null = null;
    if (saveToDb && userId && character && successCount > 0) {
      console.log(`ğŸ“¦ Auto-saving to DB (userId: ${userId}, character: ${character})...`);

      try {
        const supabase = getSupabaseClient();

        // 0. ì¹´í…Œê³ ë¦¬ ìë™ ë¶„ë¥˜
        const categories = await classifyCategories(theme || '', character);
        console.log(`ğŸ“‚ Classified categories: ${categories.join(', ')}`);

        // 1. emoticon_series ìƒì„±
        const { data: series, error: seriesError } = await supabase
          .from('emoticon_series')
          .insert({
            user_id: userId,
            theme: theme || 'Custom Sketch',
            title: `${character} - ${theme || 'Sketch'}`,
            character_description: character,
            num_scenes: successCount,
            categories, // ì¹´í…Œê³ ë¦¬ ë°°ì—´ ì €ì¥
            metadata: {
              style: style || 'pen',
              generation_method: 'pro_flux_lora',
              created_from: 'pro',
              monochromeOnly,
            },
          })
          .select()
          .single();

        if (seriesError) {
          console.error('Series creation error:', seriesError);
          throw seriesError;
        }

        savedSeriesId = series.id;

        // 2. ì„±ê³µí•œ ì´ë¯¸ì§€ë“¤ë§Œ ì €ì¥
        const successfulResults = (results as any[]).filter(r => r.success && r.transparentDataUrl);

        // Storage ì—…ë¡œë“œ (ë³‘ë ¬) + scene ë ˆì½”ë“œ ìˆ˜ì§‘ (ê°œë³„ ì‹¤íŒ¨ í—ˆìš©)
        const sceneRecords: any[] = [];

        await Promise.all(successfulResults.map(async (result, idx) => {
          try {
            const dataUrl = result.transparentDataUrl!;
            const base64Data = dataUrl.replace(/^data:image\/\w+;base64,/, '');
            const buffer = Buffer.from(base64Data, 'base64');

            // ê°ì • ì´ë¦„: emotionNames ë°°ì—´ì—ì„œ ê°€ì ¸ì˜¤ê±°ë‚˜ promptsì—ì„œ ê°€ì ¸ì˜´
            const emotionName = emotionNames?.[result.index] || prompts?.[result.index] || `Scene ${idx + 1}`;

            const fileName = `emoticons/${series.id}/scene_${result.index}.png`;
            const { error: uploadError } = await supabase.storage
              .from('images')
              .upload(fileName, buffer, {
                contentType: 'image/png',
                upsert: true,
              });

            if (uploadError) {
              console.error(`Upload error for scene ${result.index}:`, uploadError);
              return; // ì´ ì´ë¯¸ì§€ë§Œ ìŠ¤í‚µ, ë‚˜ë¨¸ì§€ ê³„ì† ì§„í–‰
            }

            const { data: urlData } = supabase.storage
              .from('images')
              .getPublicUrl(fileName);

            // ë ˆì½”ë“œ ìˆ˜ì§‘ (ë‚˜ì¤‘ì— ë‹¤ê±´ insert)
            sceneRecords.push({
              series_id: series.id,
              scene_number: result.index,
              title: emotionName,
              narrative: '',
              prompt: `${character} - ${emotionName}`,
              image_url: urlData.publicUrl,
              metadata: {
                original_style: style || 'pen',
                monochromeOnly,
              },
            });
          } catch (err: any) {
            console.error(`Failed to save scene ${result.index}:`, err.message);
            // ê°œë³„ ì‹¤íŒ¨ëŠ” ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰
          }
        }));

        // ë‹¤ê±´ insert (í•œ ë²ˆì—) - ì„±ê³µí•œ ê²ƒë“¤ë§Œ
        if (sceneRecords.length > 0) {
          const { error: scenesError } = await supabase
            .from('emoticon_scenes')
            .insert(sceneRecords);

          if (scenesError) {
            console.error('Scenes bulk insert error:', scenesError);
            // DB insert ì‹¤íŒ¨í•´ë„ ì´ë¯¸ì§€ ìƒì„± ê²°ê³¼ëŠ” ë°˜í™˜
          }
        }

        console.log(`âœ… Auto-save complete: series ${savedSeriesId}, ${sceneRecords.length}/${successfulResults.length} scenes saved`);

      } catch (saveError: any) {
        console.error('Auto-save failed:', saveError.message);
        // ì €ì¥ ì‹¤íŒ¨í•´ë„ ìƒì„± ê²°ê³¼ëŠ” ë°˜í™˜
      }
    }

    return NextResponse.json({
      success: true,
      mode,
      results,
      total: itemCount,
      successCount,
      failedCount: itemCount - successCount,
      savedSeriesId, // ì €ì¥ëœ ê²½ìš° series ID ë°˜í™˜
    });

  } catch (error: any) {
    console.error('Error converting images with FLUX LoRA:', error);
    return NextResponse.json(
      {
        error: error.message || 'Failed to convert images',
        details: error.toString(),
      },
      { status: 500 }
    );
  }
}
